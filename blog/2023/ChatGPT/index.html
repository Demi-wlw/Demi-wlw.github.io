<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    
    <!-- Website verification -->
    <meta name="google-site-verification" content="2AXgTeXWVW_0injIR91zWl2Dz2AJyUT9xr667wSGOcY">
<!-- Avoid warning on Google Chrome
        Error with Permissions-Policy header: Origin trial controlled feature not enabled: 'interest-cohort'.
        see https://stackoverflow.com/a/75119417
    -->
    <meta http-equiv="Permissions-Policy" content="interest-cohort=()">

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Understanding ChatGPT | Luwei  Wang (Demi)</title>
    <meta name="author" content="Luwei  Wang (Demi)">
    <meta name="description" content="a summary of ChatGPT and GPT techniques">
    <meta name="keywords" content="academic-website, personal-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/tiger.png">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://demi-wlw.github.io/blog/2023/ChatGPT/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "Understanding ChatGPT",
      "description": "a summary of ChatGPT and GPT techniques",
      "published": "March 19, 2023",
      "authors": [
        {
          "author": "Luwei Wang",
          "authorURL": "",
          "affiliations": [
            {
              "name": "University of Edinburgh",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Luwei </span>Wang (Demi)</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">Home</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">CV</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">Projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">Repositories</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>Understanding ChatGPT</h1>
        <p>a summary of ChatGPT and GPT techniques</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#what-is-chatgpt">What is ChatGPT?</a></div>
            <div><a href="#what-is-gpt">What is GPT?</a></div>
            <div><a href="#gpt-models">GPT Models</a></div>
            <ul>
              <li><a href="#generative-pre-training">Generative pre-training</a></li>
              <li><a href="#supervised-fine-tuning">Supervised fine-tuning</a></li>
              <li><a href="#few-shot-learning">Few-shot learning</a></li>
              
            </ul>
<div><a href="#improvements-of-gpts">Improvements of GPTs</a></div>
            
          </nav>
        </d-contents>

        <p class="text-justify">OpenAI is back in the headlines with news that it is updating its viral ChatGPT with a new version called <a href="https://openai.com/research/gpt-4" rel="external nofollow noopener" target="_blank">GPT-4</a>. If ChatGPT is the car, then GPT-4 is the engine: a powerful general technology that can be shaped down to a number of different uses. GPT-3 and now 4 are actually the internet’s best-known language-processing AI models.</p>

<h2 id="what-is-chatgpt">What is ChatGPT?</h2>

<p class="text-justify"><a href="https://chat.openai.com/chat" rel="external nofollow noopener" target="_blank">ChatGPT</a> is a large language model developed by OpenAI, which is based on the GPT (Generative Pre-trained Transformer) architecture. It is designed to understand natural language, generate human-like responses, and complete a variety of language tasks including language translation, text summarization, question-answering and more. It has been trained on a massive amount of text data from the internet, books, and other sources, allowing it to learn and understand a wide range of topics and provide informative and engaging responses.</p>

<h2 id="what-is-gpt">What is GPT?</h2>

<p class="text-justify">GPT (Generative Pre-trained Transformer) is a type of neural network architecture used for natural language processing (NLP) tasks, such as language modeling, text classification, and machine translation. It was first introduced by OpenAI in 2018, and has been used in a wide variety of applications.</p>

<p class="text-justify">The GPT architecture is based on the <strong><em>Transformer</em></strong> model, which was introduced in 2017 by Vaswani et al.<d-cite key="attension2017"></d-cite> allowing to capture long-term dependencies in text without the need for recurrent neural networks and generate high-quality language output. GPT models are <strong><em>pre-trained</em></strong> on large amounts of text data using an unsupervised learning approach, where the model is trained to <strong><em>predict the next word</em></strong> in a sequence of text. The pre-training allows the model to learn the statistical language patterns and contextual relationships within natural language text, which can then be fine-tuned on specific NLP tasks, such as language translation, text classification, and text generation with smaller amounts of labeled data.</p>

<p class="text-justify">GPT has been a major breakthrough in natural language processing and the version GPT-3 has 175 billion parameters. It has been used to achieve state-of-the-art results on a wide variety of language tasks and has been adopted by a variety of industries for language-related applications such as chatbots, text summarization, and language translation. Its ability to pre-train on large amounts of data and adapt to new tasks with few examples makes it a highly versatile and valuable tool for language-related applications.</p>

<hr>

<h2 id="gpt-models">GPT Models</h2>

<ul class="text-justify">
  <li>GPT-1 is available <a href="https://openai.com/research/language-unsupervised" rel="external nofollow noopener" target="_blank">here</a> with paper “Improving Language Understanding
by Generative Pre-Training”.</li>
  <li>GPT-2 is open-source <a href="https://openai.com/research/better-language-models" rel="external nofollow noopener" target="_blank">here</a> with paper “Language Models are Unsupervised Multitask Learners”.</li>
  <li>GPT-3 has published paper <d-cite key="GPT-3"></d-cite>.</li>
  <li>There are several other open-source GPT alternatives such as <a href="https://github.com/facebookresearch/llama" rel="external nofollow noopener" target="_blank">LLaMA</a> by Meta AI with paper “LLaMA: Open and Efficient Foundation Language Models”<d-cite key="touvron2023llama"></d-cite>.</li>
</ul>

<p class="text-justify"><strong>The first version of GPT</strong> was introduced based on the ideas of transformers<d-footnote>A good website for detailed learning can be found <a href="https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html#transformer_intro" rel="external nofollow noopener" target="_blank">here</a> <d-cite key="voita2020nlpCourse"></d-cite>.</d-footnote> and <a href="https://arxiv.org/abs/1511.01432" rel="external nofollow noopener" target="_blank">unsupervised pre-training</a>. Its results provide a convincing example that pairing supervised learning methods with unsupervised pre-training works very well. In summary, GPT as the name suggested, adopts <strong><em>generative pre-training</em></strong> of a language model on a diverse corpus of unlabeled text, followed by discriminative <strong><em>supervised fine-tuning</em></strong> on each specific task.</p>

<h3 id="generative-pre-training">Generative pre-training</h3>

<p class="text-justify">The term <em>generative pre-training</em> represents the unsupervised pre-training of the generative model.<d-footnote>They used a multi-layer Transformer decoder to produce an output distribution over target tokens.</d-footnote> Given an unsupervised corpus of tokens \(\mathcal{U} = \{u_1,\dots,u_n\}\), they use a standard language modeling objective to maximize the following likelihood:</p>

\[L_1(\mathcal{U})=\sum_i\log P(u_i|u_{i-k},\dots,u_{i-1};\Theta)\]

<p class="text-justify">where \(k\) is the size of the context window, and the conditional probability \(P\) is modeled using a neural network with parameters \(\Theta\) trained using stochastic gradient descent. <strong>Intuitively, we train the Transformer-based model to predict the next token within the \(k\)-context window using unlabeled text from which we also extract the latent features \(h\).</strong></p>

<h3 id="supervised-fine-tuning">Supervised fine-tuning</h3>

<p class="text-justify">After training the model with the objective function above, they adapte the parameters to the supervised target task which is referring to <em>supervised fine-tuning</em>. Assume a labeled dataset \(\mathcal{C}\), where each instance consists of a sequence of input tokens, \(x^1,\dots, x^m\), along with a label \(y\). The inputs are passed through the pre-trained model to obtain the final transformer block’s activation \(h_l^m\), which is then fed into an added linear output layer with parameters \(W_y\) to predict \(y\):</p>

\[P(y|x^1,\dots,x^m)=softmax(h_l^mW_y).\]

<p>This gives us the following objective to maximize:</p>

\[L_2(\mathcal{C})=\sum_{(x,y)}\log P(y|x^1,\dots,x^m)\]

<p class="text-justify">They additionally found that including language modeling as an auxiliary objective to the fine-tuning helped learning by (a) improving generalization of the supervised model, and (b) accelerating convergence. Specifically, we optimize the following objective (with weight \(\lambda\)): \(L_3(\mathcal{C})=L_2(\mathcal{C})+\lambda*L_1(\mathcal{C})\).</p>

<p class="text-justify">Some tasks, like question answering or textual entailment, have structured inputs such as ordered sentence pairs, or triplets of document, question, and answers that are different from the contiguous sequences of text inputs of pre-trained model so they require some modifications to apply GPT. This results in the <strong><em>input transformations</em></strong> which allow us to avoid making extensive changes to the architecture across tasks. A brief description of these input transformations is shown in Figure 1 (credit to the <a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" rel="external nofollow noopener" target="_blank">paper</a>).</p>

<div class="row justify-content-sm-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/GPT1_inputTrans-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/GPT1_inputTrans-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/GPT1_inputTrans-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/GPT1_inputTrans.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="GPT-1 with input transformations" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>

<p class="text-justify"><strong>GPT-3</strong> was applied with tasks and <strong><em>few-shot</em></strong> demonstrations specified purely via text interaction with the model. Since fine-tuning involves updating the weights of a pre-trained model by training on a supervised dataset specific to the desired task, it typically requires thousands to hundreds of thousands of labeled examples. However, the main disadvantages are the need for a new large dataset for every task, the potential for poor generalization out-of-distribution, and the potential to exploit spurious features of the training data, potentially resulting in an unfair comparison with human performance.</p>

<h3 id="few-shot-learning">Few-shot learning</h3>

<p class="text-justify">Few-Shot is the term referring to the setting where the model is given a few demonstrations of the task at inference time as conditioning, but no weight updates are allowed. <em>Few-shot learning</em> involves learning based on a broad distribution of tasks (in this case implicit in the pre-training data) and then rapidly adapting to a new task. The primary goal in traditional Few-Shot frameworks is to learn a similarity function that can map the similarities between the classes in the support and query sets. Figure 2.1 <d-cite key="GPT-3"></d-cite> illustrates different settings, from which we see for a typical dataset an example has a context and a desired completion (for example an English sentence and the French translation), and few-shot works by giving \(K\) examples of context and completion, and then one final example of context, with the model expected to provide the completion. The main advantages of few-shot are a major reduction in the need for task-specific data and reduced potential to learn an overly narrow distribution from a large but narrow fine-tuning dataset. The main disadvantage is that results from this method have so far been much worse than state-of-the-art fine-tuned models. Also, a small amount of task specific data is still required.</p>

<div class="row justify-content-sm-center">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/GPT3_fewShot-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/GPT3_fewShot-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/GPT3_fewShot-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/GPT3_fewShot.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="GPT-3 Few-Shot learning" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>

<hr>

<h2 id="improvements-of-gpts">Improvements of GPTs</h2>

<p class="text-justify"><strong>GPT-1</strong> employes the idea of unsupervised learning for training representations of words using large amounts of unlabeled data consisting of terabytes of information and then integrates supervised learning for fine-tuning to improve performance on a wide range of NLP tasks. However, it has drawbacks including (1) Compute requirements (expensive pre-training step) (2) The limits and bias of learning about the world through text, and (3) Still brittle generalization.</p>

<p class="text-justify"><strong>GPT-2</strong> is a larger model with 1.5 billion parameters following the details of GPT-1 (117 million parameters) with a few modifications. This larger size allows it to capture more complex language patterns and relationships. In short, GPT-2 is a direct scale-up of GPT-1, with more than \(10\times\) the parameters and trained on more than \(10\times\) the amount of data.</p>

<p><strong>GPT-3</strong> uses a variety of techniques to improve performance, including:</p>
<ol class="text-justify">
  <li>Larger size: has 175 billion parameters which allows to capture even more complex language patterns and relationships.</li>
  <li>Adaptive computation: dynamically adjusts the number of parameters used for each task, allowing it to allocate more resources to complex tasks and fewer resources to simpler tasks.</li>
  <li>Few-shot learning: learns to perform a new task with just a few examples, making it highly flexible and adaptable to new tasks and contexts.</li>
  <li>Prompt engineering: can be given a natural language prompt to generate text that fits a specific context or follows a specific style.</li>
</ol>


      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/2023-03-19-ChatGPT.bib"></d-bibliography>

      <div style="max-width: 1000px; margin: 0 auto; margin-bottom: 50px;">


  
    
    <br>
    <hr>
    <br>
    <ul class="list-disc pl-8"></ul>

    <!-- Adds related posts to the end of an article -->
    <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2>
    <p class="mb-2">Here are some more articles you might like to read next:</p>
  

  <li class="my-2">
    <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/Latex-symbols/">Summary of Latex code for symbols</a>
  </li>


      </div>
<div id="giscus_thread" style="max-width: 1000px; margin: 0 auto;">
  <script>
    let giscusTheme = localStorage.getItem("theme");
    let giscusAttributes = {
        "src": "https://giscus.app/client.js",
        "data-repo": "Demi-wlw/Demi-wlw.github.io",
        "data-repo-id": "R_kgDOIh5mVw",
        "data-category": "Comments",
        "data-category-id": "DIC_kwDOIh5mV84CUz5b",
        "data-mapping": "title",
        "data-strict": "1",
        "data-reactions-enabled": "1",
        "data-emit-metadata": "0",
        "data-input-position": "bottom",
        "data-theme": giscusTheme,
        "data-lang": "en",
        "crossorigin": "anonymous",
        "async": "",
    };


    let giscusScript = document.createElement("script");
    Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
    document.getElementById("giscus_thread").appendChild(giscusScript);
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a>
</noscript>
</div>
</div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 Luwei  Wang (Demi). Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>.
Last updated: March 21, 2023.
      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
